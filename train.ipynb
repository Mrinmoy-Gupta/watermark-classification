{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13x2vByWhz-m"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as k\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_XTGE-unh-xy"
   },
   "outputs": [],
   "source": [
    "data_dir = 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AHFKLRpuiany"
   },
   "source": [
    "# Dense Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sMstuZSkh-10",
    "outputId": "32c8d7cb-df11-41b1-c41f-b650153c63e5"
   },
   "outputs": [],
   "source": [
    "#Loading the data\n",
    "data= tf.keras.utils.image_dataset_from_directory(data_dir, seed=42, image_size=(224, 224), label_mode='binary')\n",
    "\n",
    "#scaling the data\n",
    "scaled_data = data.map(lambda x, y:(x/255, y))\n",
    "\n",
    "#Defining split sizes and splitting the data\n",
    "train_size = int(len(data)*.7)\n",
    "test_size = int(len(data)*.1)+2\n",
    "val_size = int(len(data)*.2)\n",
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)\n",
    "print(train_size+ test_size+ val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAL6WgDNh-5Z"
   },
   "outputs": [],
   "source": [
    "#Initializing the densenet model\n",
    "img_inputs = Input(shape=(224, 224, 3), name='data')\n",
    "base_model = k.applications.DenseNet121(include_top=False, input_tensor=img_inputs, input_shape=(224,224,3), pooling='max')\n",
    "\n",
    "#Making the base model layers Non-Trainable\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-AydkwXh-8t"
   },
   "outputs": [],
   "source": [
    "model = k.Sequential()\n",
    "model.add(base_model)\n",
    "\n",
    "model.add(k.layers.Flatten())\n",
    "model.add(k.layers.BatchNormalization())\n",
    "model.add(k.layers.Dense(256, activation='relu'))\n",
    "model.add(k.layers.Dropout(0.6))\n",
    "model.add(k.layers.BatchNormalization())\n",
    "model.add(k.layers.Dense(128, activation='relu'))\n",
    "model.add(k.layers.Dropout(0.4))\n",
    "model.add(k.layers.BatchNormalization())\n",
    "model.add(k.layers.Dense(64, activation='relu'))\n",
    "model.add(k.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile('adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEDCNAA7h_AB"
   },
   "outputs": [],
   "source": [
    "#Training\n",
    "history = model.fit(train, epochs=epochs, validation_data=val, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9kD4mgEqh_DN"
   },
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model.save('models/densenet.h5', save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORKmlXLch_Gl"
   },
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "recall = Recall()\n",
    "Acc = BinaryAccuracy()\n",
    "\n",
    "loaded_densenet_model = load_model('models/densenet.h5')\n",
    "\n",
    "for Batch in test.as_numpy_iterator():\n",
    "    x, y = Batch\n",
    "    y_pred = loaded_densenet_model.predict(x, verbose=0, use_multiprocessing=True)\n",
    "    pre.update_state(y, y_pred)\n",
    "    recall.update_state(y, y_pred)\n",
    "    Acc.update_state(y, y_pred)\n",
    "\n",
    "print(f\"precision:{(pre.result()*100):.2f}, recall:{(recall.result()*100):.2f}, accuracy:{(Acc.result()*100):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMk48wu6j_bi"
   },
   "source": [
    "# **InceptionV3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_vxSjUhGh_J5"
   },
   "outputs": [],
   "source": [
    "#Loading and Scaling the data\n",
    "data= tf.keras.utils.image_dataset_from_directory(data_dir, seed=42, image_size=(299, 299), label_mode='binary')\n",
    "scaled_data = data.map(lambda x, y:(x/255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HGBAPWWSh_NU"
   },
   "outputs": [],
   "source": [
    "train_size = int(len(data)*.7)\n",
    "test_size = int(len(data)*.1)+2\n",
    "val_size = int(len(data)*.2)\n",
    "\n",
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)\n",
    "\n",
    "print(train_size+ test_size+ val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6R27htAzh_Qt"
   },
   "outputs": [],
   "source": [
    "img_inputs = Input(shape=(299, 299, 3), name='data')\n",
    "inc_base_model = k.applications.InceptionV3(include_top=False, input_tensor=img_inputs, input_shape=(299,299,3))\n",
    "inc_base_model.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJHIwEqhh_UE"
   },
   "outputs": [],
   "source": [
    "inc_model = k.Sequential()\n",
    "inc_model.add(inc_base_model)\n",
    "\n",
    "inc_model.add(k.layers.Flatten())\n",
    "inc_model.add(k.layers.BatchNormalization())\n",
    "\n",
    "inc_model.add(k.layers.Dense(512, activation='relu'))\n",
    "inc_model.add(k.layers.Dropout(0.3))\n",
    "inc_model.add(k.layers.BatchNormalization())\n",
    "\n",
    "inc_model.add(k.layers.Dense(1, activation='sigmoid'))\n",
    "inc_model.compile('adam', loss = tf.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "epoch=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQyfPigFh_Xe"
   },
   "outputs": [],
   "source": [
    "inc_history = inc_model.fit(train, epochs=epochs, validation_data=val, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPo_VgTYh_a4"
   },
   "outputs": [],
   "source": [
    "inc_model.save('models/ncV3.h5', save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IMndYIdDh_d6"
   },
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "recall = Recall()\n",
    "Acc = BinaryAccuracy()\n",
    "\n",
    "loaded_inc_model = load_model('models/incv3')\n",
    "\n",
    "for Batch in test.as_numpy_iterator():\n",
    "    x, y = Batch\n",
    "    y_pred = loaded_inc_model.predict(x, verbose=0, use_multiprocessing=True)\n",
    "    pre.update_state(y, y_pred)\n",
    "    recall.update_state(y, y_pred)\n",
    "    Acc.update_state(y, y_pred)\n",
    "\n",
    "print(f\"precision:{(pre.result()*100):.2f}, recall:{(recall.result()*100):.2f}, accuracy:{(Acc.result()*100):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ZCxwnCoh_hC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbcZwpHVms7b"
   },
   "source": [
    "# **VGG16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RdtVK4H7h_nR"
   },
   "outputs": [],
   "source": [
    "# !pip install -q tensorflow-io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7D6cimIh_kI"
   },
   "outputs": [],
   "source": [
    "data= tf.keras.utils.image_dataset_from_directory(data_dir, seed=42, image_size=(224, 224), label_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uFhYv9oJh_qZ"
   },
   "outputs": [],
   "source": [
    "import tensorflow_io as tfio\n",
    "scaled_data = data.map(lambda x, y:(tfio.experimental.color.rgb_to_bgr(x), y))\n",
    "scaled_data = scaled_data.map(lambda x, y:(x/255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQh-8qndh_tW"
   },
   "outputs": [],
   "source": [
    "train_size = int(len(data)*.7)\n",
    "test_size = int(len(data)*.1)+2\n",
    "val_size = int(len(data)*.2)\n",
    "print(train_size+ test_size+ val_size)\n",
    "train = scaled_data.take(train_size)\n",
    "val = scaled_data.skip(train_size).take(val_size)\n",
    "test = scaled_data.skip(train_size+val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0GGWidBOmbOc"
   },
   "outputs": [],
   "source": [
    "img_inputs = Input(shape=(224, 224, 3), name='data')\n",
    "vgg_base_model = k.applications.vgg16.VGG16(include_top=False, input_tensor=img_inputs, input_shape=(224,224,3))\n",
    "vgg_base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sfdungZxmbTV"
   },
   "outputs": [],
   "source": [
    "vgg_model = k.Sequential()\n",
    "vgg_model.add(vgg_base_model)\n",
    "vgg_model.add(k.layers.Flatten())\n",
    "vgg_model.add(k.layers.BatchNormalization())\n",
    "vgg_model.add(k.layers.Dense(256, activation='relu'))\n",
    "vgg_model.add(k.layers.Dropout(0.4))\n",
    "vgg_model.add(k.layers.BatchNormalization())\n",
    "vgg_model.add(k.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IiVyxWs3mbWh"
   },
   "outputs": [],
   "source": [
    "epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cqy97YeCmbZq"
   },
   "outputs": [],
   "source": [
    "vgg_history = vgg_model.fit(train, epochs=epochs, validation_data=val, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pBkdiMDmmbcv"
   },
   "outputs": [],
   "source": [
    "vgg_model.save('vgg16.h5', save_format='h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQA62nPSmoFR"
   },
   "outputs": [],
   "source": [
    "\n",
    "pre = Precision()\n",
    "recall = Recall()\n",
    "Acc = BinaryAccuracy()\n",
    "\n",
    "vgg_loaded_model = load_model('models/vgg16_v2.h5')\n",
    "\n",
    "for Batch in test.as_numpy_iterator():\n",
    "    x, y = Batch\n",
    "    y_pred = vgg_loaded_model.predict(x, verbose=0, use_multiprocessing=True)\n",
    "    pre.update_state(y, y_pred)\n",
    "    recall.update_state(y, y_pred)\n",
    "    Acc.update_state(y, y_pred)\n",
    "\n",
    "print(f\"precision:{(pre.result()*100):.2f}, recall:{(recall.result()*100):.2f}, accuracy:{(Acc.result()*100):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aj0f3-HBmoIo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hx-CO6VtmoZT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
